# IO configuration
iotool:
  batch_size: 16
  shuffle: false
  num_workers: 0
  collate_fn: all
  sampler:
    name: random_sequence
    seed: 0
  dataset:
    name: larcv
    file_keys:
      - /sdf/data/neutrino/sbnd/simulation/mpvmpr_v00/train/larcv_training_batch_0.root
    schema:
      data:
        parser: parse_cluster3d
        cluster_event: cluster3d_pcluster
        particle_event: particle_corrected
        sparse_semantics_event: sparse3d_pcluster_semantics
        sparse_value_event: sparse3d_reco_rescaled
        add_particle_info: true
        break_clusters: true
      coord_label:
        parser: parse_particle_coords
        particle_event: particle_corrected
        cluster_event: cluster3d_pcluster

# Model configuration
model:
  name: grappa
  modules:
    grappa:
      nodes:
        source: 5
        semantic_class: [0, 2, 3]
        min_size: -1
        make_groups: true
        grouping_method: score
      graph:
        name: complete
        max_length: [500, 0, 500, 500, 0, 0, 0, 25, 0, 25]
        dist_algorithm: recursive
      node_encoder:
        name: geo
        use_numpy: true
        add_value: true
        add_shape: true
        add_points: true
        add_local_dirs: true
        dir_max_dist: 5
        add_local_dedxs: true
        dedx_max_dist: 5
      edge_encoder:
        name: geo
        use_numpy: true
      gnn_model:
        name: meta
        node_feats: 33 # 16 (geo) + 3 (extra) + 6 (points) + 6 (directions) + 2 (local dedxs)
        edge_feats: 19
        node_pred: 2
        edge_pred: 2
        edge_layer:
          name: mlp
          mlp:
            depth: 3
            width: 64
            activation:
              name: lrelu
              negative_slope: 0.1
            normalization: batch_norm
        node_layer:
          name: mlp
          reduction: max
          attention: false
          message_mlp:
            depth: 3
            width: 64
            activation:
              name: lrelu
              negative_slope: 0.1
            normalization: batch_norm
          aggr_mlp:
            depth: 3
            width: 64
            activation:
              name: lrelu
              negative_slope: 0.1
            normalization: batch_norm

    grappa_loss:
      node_loss:
        name: shower_primary
        high_purity: true
        use_group_pred: true
      edge_loss:
        name: channel
        target: 7
        high_purity: true

  network_input:
    data: data
    coord_label: coord_label
  loss_input:
    clust_label: data

# Training regimen configuration
trainval:
  seed: 0
  gpus: '0'
  unwrap: false
  weight_prefix: snapshot
  iterations: 10
  report_step: 1
  checkpoint_step: 10
  model_path: null
  log_dir: .
  train: true
  optimizer:
    name: Adam
    lr: 0.001
